{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up\n",
    "\n",
    "Create a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=1000)\n",
    "\n",
    "r2_scores = dict()  # We will hold results here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a Random Forest to model the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(oob_score=True, n_estimators=100, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benchmark           0.678078\n",
       "Pipeline Overfit    0.979797\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)\n",
    "r2_scores['Benchmark'] = model.oob_score_\n",
    "pd.Series(r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the Transformer to calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "from QuantileCalibrator import QuantileCalibrator\n",
    "\n",
    "# Hacky way to change a RandomForest into a Transformer\n",
    "class RandomForestTransformer(RandomForestRegressor, TransformerMixin):\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestTransformer(oob_score=True, n_estimators=100)\n",
    "qc = QuantileCalibrator(quantile=100, isotonic_fit=True, isotonic_lambda=1)\n",
    "\n",
    "steps = [\n",
    "    ('random_forest', rf),\n",
    "    ('quantile_cal', qc)\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('random_forest', RandomForestTransformer(bootstrap=True, criterion='mse', max_depth=None,\n",
       "            max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction...t=False)), ('quantile_cal', QuantileCalibrator(isotonic_fit=True, isotonic_lambda=1, quantile=100))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring like this will result in over fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benchmark           0.681189\n",
       "Pipeline Overfit    0.979797\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_scores['Pipeline Overfit'] = pipeline.score(X, y)\n",
    "pd.Series(r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can instead use the out-of-bag predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benchmark           0.678078\n",
       "Pipeline OOB        0.738246\n",
       "Pipeline Overfit    0.979797\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_scores['Pipeline OOB'] = qc.score(rf.oob_prediction_, y)\n",
    "pd.Series(r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validate Results\n",
    "\n",
    "Alternatively, we can use $k$-fold cross validation on the entire pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benchmark              0.678078\n",
       "Pipeline 10 Fold CV    0.718343\n",
       "Pipeline OOB           0.738246\n",
       "Pipeline Overfit       0.979797\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validated_scores = cross_val_score(X=X, y=y, cv=10, estimator=pipeline, n_jobs=-1)\n",
    "r2_scores['Pipeline 10 Fold CV'] = cross_validated_scores.mean()\n",
    "pd.Series(r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Search: 2 Steps\n",
    "\n",
    "We can now optimize to find the best hyper parameters.\n",
    "\n",
    "First, we'll do this with only the Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\n",
    "    'n_estimators': randint(10, 1000),\n",
    "    'max_features': uniform(0, 1)\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=search_params, n_iter=30, n_jobs=-1, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.8041407631899328, 'n_estimators': 892}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result = random_search.fit(X, y)\n",
    "search_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benchmark                   0.678078\n",
       "Pipeline 10 Fold CV         0.718343\n",
       "Pipeline Best HP 2 steps    0.744184\n",
       "Pipeline OOB                0.738246\n",
       "Pipeline Overfit            0.979797\n",
       "RF Only, Best HPs           0.694573\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on the full dataset\n",
    "rf.set_params(oob_score=True, **search_result.best_params_)\n",
    "rf.fit(X, y)\n",
    "r2_scores['RF Only, Best HPs'] = rf.oob_score_\n",
    "pd.Series(r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can fit a quantile calibrator using these parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestTransformer()\n",
    "qc = QuantileCalibrator()\n",
    "\n",
    "pipeline = Pipeline(steps=[('random_forest', rf), ('quantile_calibrator', qc)], memory='.')\n",
    "\n",
    "# We only need to fit params for the QuantileCalibrator because the RandomForest was already fit above.\n",
    "search_params = {\n",
    "    'random_forest__max_features': [search_result.best_params_['max_features']],\n",
    "    'random_forest__n_estimators': [search_result.best_params_['n_estimators']],\n",
    "    'quantile_calibrator__quantile': randint(10, 300),\n",
    "    'quantile_calibrator__isotonic_fit': [True, False],\n",
    "    'quantile_calibrator__isotonic_lambda': uniform(0.01, 20)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, \n",
    "                                   param_distributions=search_params, \n",
    "                                   n_iter=30, \n",
    "                                   n_jobs=-1,\n",
    "                                   verbose=1,\n",
    "                                   cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 1.76s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 2.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 3.97s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 3.68s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 4.89s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 2.62s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 3.88s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 2.10s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 2.79s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 2.70s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 3.21s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 1.88s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 1.18s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 4.63s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 3.11s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 5.66s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 5.12s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 3.26s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 3.26s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 1.44s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 2.37s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 1.22s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 5.21s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 1.14s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 1.10s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 5.04s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 1.25s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 0.57s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 1.30s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 2.92s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 2.10s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 4.52s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 4.88s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 4.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 0.67s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 1.41s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "search_result2 = random_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quantile_calibrator__isotonic_fit': True,\n",
       " 'quantile_calibrator__isotonic_lambda': 5.218566439308666,\n",
       " 'quantile_calibrator__quantile': 45,\n",
       " 'random_forest__max_features': 0.8041407631899328,\n",
       " 'random_forest__n_estimators': 892}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benchmark                   0.678078\n",
       "Pipeline 10 Fold CV         0.718343\n",
       "Pipeline Best HP 2 steps    0.745952\n",
       "Pipeline OOB                0.738246\n",
       "Pipeline Overfit            0.979797\n",
       "RF Only, Best HPs           0.694573\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on the full dataset\n",
    "pipeline.set_params(random_forest__oob_score=True, **search_result2.best_params_)\n",
    "pipeline.fit(X, y)\n",
    "rf_pred = pipeline.named_steps['random_forest'].oob_prediction_\n",
    "r2_scores['Pipeline Best HP 2 steps'] = pipeline.named_steps['quantile_calibrator'].score(rf_pred, y)\n",
    "pd.Series(r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Search: 1 Step\n",
    "\n",
    "We can also search for the best HPs for both stages of the pipeline simultaniously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestTransformer()\n",
    "qc = QuantileCalibrator()\n",
    "\n",
    "pipeline = Pipeline(steps=[('random_forest', rf), ('quantile_calibrator', qc)], memory='.')\n",
    "\n",
    "# We only need to fit params for the QuantileCalibrator because the RandomForest was already fit above.\n",
    "search_params = {\n",
    "    'random_forest__max_features': uniform(0.1, 0.9),\n",
    "    'random_forest__n_estimators': randint(10, 1000),\n",
    "    'random_forest__n_jobs': [-1],\n",
    "    'quantile_calibrator__quantile': randint(10, 300),\n",
    "    'quantile_calibrator__isotonic_fit': [True, False],\n",
    "    'quantile_calibrator__isotonic_lambda': uniform(0.01, 20)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, \n",
    "                                   param_distributions=search_params, \n",
    "                                   n_iter=30, \n",
    "                                   n_jobs=-1,\n",
    "                                   verbose=1,\n",
    "                                   cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 0.66s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 0.84s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:   55.0s\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 0.80s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:213: UserWarning: Persisting input arguments took 1.29s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'quantile_calibrator__isotonic_fit': True,\n",
       " 'quantile_calibrator__isotonic_lambda': 17.021233519809098,\n",
       " 'quantile_calibrator__quantile': 188,\n",
       " 'random_forest__max_features': 0.4543227398403513,\n",
       " 'random_forest__n_estimators': 851,\n",
       " 'random_forest__n_jobs': -1}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result3 = random_search.fit(X, y)\n",
    "search_result3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benchmark                   0.678078\n",
       "Pipeline 10 Fold CV         0.718343\n",
       "Pipeline Best HP 1 step     0.737662\n",
       "Pipeline Best HP 2 steps    0.745952\n",
       "Pipeline OOB                0.738246\n",
       "Pipeline Overfit            0.979797\n",
       "RF Only, Best HPs           0.694573\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_scores['Pipeline Best HP 1 step'] = search_result3.best_score_.mean()\n",
    "pd.Series(r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
